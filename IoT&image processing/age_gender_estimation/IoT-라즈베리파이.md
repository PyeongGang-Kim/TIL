# IoT - 라즈베리파이

이 프로젝트에서 라즈베리파이는 아두이노보드에서 블루투스로 전송한 조이스틱 데이터를 받아와서 화면의 마우스 포인터를 조작하고, 웹캠으로부터 이미지를 가져와 이미지 처리 라이브러리를 활용하여 얼굴을 인식하고, 나이와 성별 정보를 추정하여 서버로 전송하는 역할을 한다.

이를 통해 현재 사용중인 사람의 나이, 성별에 맞는 추천 설문을 제공할 수 있을 것으로 기대한다.



## 준비사항 - 라이브러리

pyautogui: 라즈베리파이의 마우스 포인터를 조작하기 위한 라이브러리

bluetooth: 블루투스 통신을 위한 라이브러리

cv2: openCV. 이미지 프로세싱을 위한 라이브러리이다.

dlib: 이 라이브러리는 얼굴을 찾아내는데 사용된다.

requests: 이 라이브러리는 기기에서 인식된 나이, 성별 정보를 서버로 전송하기 위하여 사용된다.

json: 전송하는 데이터를 객체가 아닌 json타입의 스트링으로 변환하기 위하여 사용된다.



## 블루투스 데이터 수신

블루투스 데이터를 수신하기 위해서 소켓을 열어준다.

블루투스 소켓은 bluetooth 라이브러리 안의 BluetoothSocket을 사용하여 열 수 있다.

```python
rasp_socket=BluetoothSocket( RFCOMM )
rasp_socket.connect(("00:19:10:08:58:C7", 1))
```

RFCOMM 프로토콜을 이용한 블루투스 소켓을 열고 맥 주소 10:19:10:08:58:C7을 가진 기기와 연결을 시키는 부분이다.

이렇게 하면 00:19:10:08:58:C7 기기에서 보낸 데이터를 받을 준비를 마치게 된다.



## 받아온 데이터를 통해 마우스 포인터 조작

아두이노 보드가 보낸 데이터는 아래와 같이 받아올 수 있다.

```python
a = list(rasp_socket.recv(1024)) 
```

rasp_socket.recv(1024) 의 경우 소켓으로부터 데이터를 1024바이트 읽어오겠다는 의미이다.

소켓은 바이트 단위로 데이터를 전송하는데 list로 받으면 이 데이터가 바이트단위로 정수형으로 자동적으로 변환이 되기 때문에 list로 감싸 주었다.

이렇게 받아온 데이터는

x축변위, y축변위, 버튼, x축변위, y축변위, 버튼... 이런식으로 3 바이트 단위로 변위와 눌려진 버튼에 대한 정보를 담고 있다.



pyautogui를 pg라는 이름으로 받아왔기 때문에 pg를 사용한다.

pg.position()은 마우스 포인터의 현재 위치를 가져온다는 의미이다.

pg.moveTo(x, y)의 경우 마우스 포인터를 x, y좌표로 이동시킨다는 의미이다. 블루투스로부터 받아온 x축변위와 y축변위에 해당하는 만큼 적절하게 조작을 하면 될 것이다. 다만 이 조작에는 딜레이가 존재한다. default 값은 0.1초이고 pg.PAUSE = 0.01을 실행하면 딜레이가 0.01초로 변하게 된다.

pg.FAILSAFE는 기본적으로 True 값을 가진다. 이 경우 마우스 포인터를 화면 이상으로 조작하려고 하면 오류를 발생시킨다. pg.FAILSAFE = False를 입력하여 이러한 오류를 무시할 수 있다.



## 이미지 프로세싱

이미지를 프로세싱하기 위해서는 우선 이미지를 읽어와야 한다.

openCV의 VideoCapture 기능을 활용하여 웹캠의 이미지를 받아올 수 있다.

cap = cv2.VideoCapture("http://192.168.137.252:8080/video")

"http://192.168.137.252:8080/video"이라는 주소에서 이미지를 캡처해 올 것이라고 선언하는 부분이다.

cap.read()를 하면 위에 선언한 경로로부터 이미지를 캡쳐해서 가져온다. 반환 값은 두개인데 두번째 값이 캡처해온 이미지의 데이터를 담고 있는 부분이다.

cap.release()를 하면 비디오 캡쳐를 멈추겠다는 의미이다.

detector은 dlib의 얼굴 식별기이다. 이미지 데이터를 넣어주면 식별된 얼굴들을 왼쪽 위 점의 x, y좌표 오른쪽 아래 점의 x, y좌표 순으로 네개의 값을 가진 얼굴 정보들이 담긴 배열을 반환한다.



이제 원본 이미지에서 얼굴이 어떤 위치에 존재하는지 알게 되었다. 얼굴에 해당하는 부분들만 잘라서 성별과 나이를 식별하는데 사용할 것이다.

face_img = img[y1:y2, x1:x2].copy()

원래 이미지에서 식별된 얼굴에 해당하는 부분을 face_img라는 변수에 담는 것이다.

```python
blob = cv2.dnn.blobFromImage(
                            face_img,
                            scalefactor=1,
                            size=(227, 227),
                            mean=(78.4263377603, 87.7689143744, 114.895847746),
                            swapRB=False,
                            crop=False)
```

이 부분에서는 face_img에서 나이 성별 정보를 추정하기 위한 전 처리를 하는 것이다.

첫번째 변수는 이미지 데이터이다.

scalefactor은 뺄 값에 곱할 값이다. mean값에 대해 설명할 때 같이 다루겠다.

size은 반환할 이미지의 크기를 정해주는 부분이다. 우리가 가져온 얼굴은 각 각 사이즈가 다르다. 따라서 이 크기를 동일하게 만들어 주어야 한다.

mean은 각 픽셀에서 r, g, b에 얼마만큼을 빼 줄 것인지에 대한 정보이다. 모든 픽셀들에서 red값을 r만큼, green값을 g만큼 blue값을 b만큼 빼 주겠다는 의미이다.

swapRB가 TRUE이면 입력받는 이미지가 r, g, b가 아니라 b, g, r 순으로 들어온다고 알려주는 것이다.



이렇게 전처리된 이미지를 기 학습된 신경망에 넣어 결과를 받아올 수 있다.

```python
age_net = cv2.dnn.readNetFromCaffe(
	'models/deploy_age.prototxt', 
    'models/age_net.caffemodel'
)
gender_net = cv2.dnn.readNetFromCaffe(
    'models/deploy_gender.prototxt', 
	'models/gender_net.caffemodel'
)
```

age_net은 기존에 학습된 age_net.caffemodel정보와 deploy_age.prototxt에 정의된 레이어층을 사용하여 이미지를 처리하겠다는 선언을 하는 부분이다. gender_net도 이와 유사하다.

직접 학습시키지는 않고 기 학습된 데이터, 정의된 레이어를 사용하였다.

age_net.setInput(전처리된 이미지)

이 명령으로 age_net으로 전처리된 이미지를 처리할 것이라고 알려준 후

age_net.forward()을 하면 각 라벨별로 확률 값이 나오게 된다. 이미지가 처리된 후 정보를 반환한다.

이 정보중 첫번째 값이 기존에 정의한 라벨에 대한 각 각의 확률을 의미한다.

기존에 정의한 라벨(나이)

```python
age_list = ['(0, 2)','(4, 6)','(8, 12)','(15, 20)','(25, 32)','(38, 43)','(48, 53)','(60, 100)']
```

이렇게 여러게의 라벨에 해당하는 확률이 나오는데 이것을 argmax를 이용하면 가장 높은 확률의 인덱스 번호를 반환한다.

이렇게 반환된 인덱스 번호에 해당하는 라벨 데이터를 가져오면 이미지로부터 나이를 추정한 결과를 받게 되는 것이다.

성별에 대한 정보도 이와 비슷하게 받아올 수 있다.



## 추정한 성별, 나이 정보를 서버로 전송하기

성별과 나이 정보를 data 객체에 담아 준다. 기기 번호는 각 기기별 고유 번호이다.

```python
data = {
	'gender': gender_list.index(gender)+1,
    'age': age_avg[age_list.index(age)],
    'device': device_number,
}
```

이렇게 하면 우리가 보낼 데이터를 객체에 다 담았다.

RESTapi 서버에서는 이러한 객체를 받는 것이 아니라 json 타입의 데이터를 받아오기 때문에 이를 json 객체로 변환시켜 줘야 한다.

jsondata = json.dumps(data)

이 json 데이터를 request 모듈을 사용해 포스트 요청으로 보내면 끝난다.

requests.post('보낼 url', json=jsondata)



